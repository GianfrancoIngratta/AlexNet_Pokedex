{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jabb4/AlexNet_Pokedex/blob/main/myPokedex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFIkdD-6_-xj"
      },
      "source": [
        " # Pokemon Images classification using AlexNet-based CNN architecture\n",
        "\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JbcmvUtONsCY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n",
            "/home/jack/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#!pip3 install opendatasets\n",
        "#!pip3 install import_ipynb\n",
        "!pip3 install kaggle\n",
        "import import_ipynb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import time \n",
        "\n",
        "from os import listdir\n",
        "import os\n",
        "import cv2 as cv\n",
        "import glob\n",
        "import opendatasets as od\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import lr_scheduler \n",
        "from torchvision import transforms, utils\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.io import read_image\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from skimage import io, transform\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V6RDOURCwS6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from /home/jack/myPokedex/AlexNet_Pokedex/tools/AlexNet.ipynb\n",
            "importing Jupyter notebook from /home/jack/myPokedex/AlexNet_Pokedex/tools/images_tools.ipynb\n"
          ]
        }
      ],
      "source": [
        "# model = AlexNet.AlexNet()\n",
        "import  sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab_Notebooks/project_exam/AlexNet_Pokedex/')\n",
        "from tools.AlexNet import AlexNet\n",
        "from tools.images_tools import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhfCG0Kr553X",
        "outputId": "065879f8-5bde-415a-a1c7-a06f71ff85f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: "
          ]
        }
      ],
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/thedagger/pokemon-generation-one\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWl6s9Yg9eQQ",
        "outputId": "4ccc8c36-2963-4f5e-8aa0-8a125379cdc8"
      },
      "outputs": [],
      "source": [
        "root_path = '/content/drive/MyDrive/Colab_Notebooks/project_exam/AlexNet_Pokedex/pokemon-generation-one/dataset/'\n",
        "classes = os.listdir(root_path)\n",
        "count=0\n",
        "count_dict = {}\n",
        "print(f'Total number of pokemons: {len(classes)}')\n",
        "for pokemon in classes:\n",
        "    dir_path = os.path.join(root_path, pokemon)\n",
        "    count+=len(os.listdir(dir_path))\n",
        "    count_dict[pokemon] = len(os.listdir(dir_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "6OC4hVmQ9uyX",
        "outputId": "88dcada3-3d32-48e6-fd85-901a57cce8ea"
      },
      "outputs": [],
      "source": [
        "pd.Series(count_dict).sort_values(ascending=False).plot.bar(figsize=(30,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQU7UDWIa2s6"
      },
      "outputs": [],
      "source": [
        "from torch.nn.common_types import Tensor\n",
        "class PokemonImageDataset(Dataset):\n",
        "  \"\"\" Pokemon images dataset \"\"\"\n",
        "  \n",
        "  def __init__(self, list_of_pokemon_images, images_labels, transform = None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        list_of_pokemon_images    list[string]: list of pokemon file path\n",
        "        images_labels             list[string]: list of pokemon labels for each image\n",
        "        transform                 (callable, optional): Optional transform to be applied on a semple\n",
        "    \"\"\"\n",
        "    self.list_of_pokemon_images = list_of_pokemon_images\n",
        "    self.images_labels          = images_labels\n",
        "    self.transform              = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    \" returns the number of samples (images) in our dataset. \"\n",
        "    return len(self.list_of_pokemon_images)\n",
        "  \n",
        "  def __getitem__(self, idx : int) -> dict:\n",
        "    \"\"\"\n",
        "    The __getitem__ function loads and returns a sample from the dataset at the given index idx. \n",
        "    Based on the index, it identifies the imageâ€™s location on disk, converts that to a tensor using read_image, \n",
        "    retrieves the corresponding label, \n",
        "    calls the transform functions on them (if applicable), and returns the tensor image and corresponding label in a dictionary.\n",
        "    \"\"\"\n",
        "    if torch.is_tensor(idx): idx = idx.tolist()\n",
        "    \n",
        "    try: \n",
        "      image = read_image(self.list_of_pokemon_images[idx])\n",
        "      label = self.images_labels[idx]\n",
        "    except:\n",
        "      image = read_image(self.list_of_pokemon_images[0])\n",
        "      # print(f\"image type {image.dtype}\")\n",
        "      label = self.images_labels[0]\n",
        "\n",
        "    nof_channels = image.shape[0]\n",
        "\n",
        "    if(nof_channels == 4): #deal with 4 channels -> cut 1 channel\n",
        "      image = image[:3,:]\n",
        "    elif(nof_channels == 1): #deal with 1  channels -> extend to 3 channels (2 redundant)\n",
        "      image = image.expand(3,*image.shape[1:])\n",
        "\n",
        "\n",
        "    sample = {\"image\":image, \"label\":label}\n",
        "    \n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "    return sample\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE3USbVn-KoZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJU7tcv1qu7a"
      },
      "outputs": [],
      "source": [
        "root_path = '/content/drive/MyDrive/Colab_Notebooks/project_exam/AlexNet_Pokedex/pokemon-generation-one/dataset/'\n",
        "\n",
        "list_of_pokemons=['Mewtwo', 'Pikachu', 'Charmander', 'Bulbasaur', 'Squirtle']\n",
        "\n",
        "numerical_label = dict(zip(list_of_pokemons,range(len(list_of_pokemons))))\n",
        "\n",
        "list_of_images = [file for pokemon in list_of_pokemons for file in glob.glob(root_path + pokemon + \"/*\")]\n",
        "\n",
        "list_of_labels = []\n",
        "\n",
        "for image_path in list_of_images:\n",
        "  for name, label in numerical_label.items():\n",
        "    if name in image_path: list_of_labels.append(numerical_label[name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX_N5Q8IMuMu",
        "outputId": "19ec902d-2dbc-406c-ff7c-e65ca876c1dd"
      },
      "outputs": [],
      "source": [
        "print(f\"example: image -> {list_of_images[0]}, label -> {list_of_labels[0]}\")\n",
        "print(f\"example: image -> {list_of_images[1000]}, label -> {list_of_labels[1000]}\")\n",
        "print(f\"number of images : {len(list_of_images)}, number of labels : {len(list_of_labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRLyEsnjUmgy"
      },
      "outputs": [],
      "source": [
        "pokemon_dataset = PokemonImageDataset(list_of_images, list_of_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "7xM9gwQp-S5a",
        "outputId": "a83f98f3-4072-45b9-8db2-268d65313844"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(1,4,figsize=(12,8))\n",
        "\n",
        "for i, sample in enumerate(pokemon_dataset):\n",
        "  print(\"sample : \", i, sample['image'].shape)\n",
        "  plt.tight_layout()\n",
        "  ax[i].set_title('Sample #{}'.format(i))\n",
        "  # ax[i].axis('off')\n",
        "  \n",
        "  try:\n",
        "    ax[i].imshow(sample[\"image\"])\n",
        "  except:\n",
        "    ax[i].imshow(sample[\"image\"][0])\n",
        "    # print(\"4 images resized to 3 k\")\n",
        "  if i==3: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMwca4LCKqEn"
      },
      "outputs": [],
      "source": [
        "scale = Rescale(256)\n",
        "crop = RandomCrop(128)\n",
        "composed = transforms.Compose([Rescale(256), RandomCrop(224)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "XIvrqSK5Ljp5",
        "outputId": "2c5dfe04-4c32-4501-ad34-4ee0268a2e06"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(1,4,figsize=(20,10))\n",
        "\n",
        "sample = pokemon_dataset[38] # what if image has 4k resolution ?\n",
        "\n",
        "ax[0].imshow(sample[\"image\"].transpose(0,1).transpose(1,2))\n",
        "ax[0].set_title(\"Original\")\n",
        "\n",
        "for i, tsfrm in enumerate([scale, crop, composed]):  \n",
        "  transformed_sample = tsfrm(sample)\n",
        "  # if(i==2):\n",
        "  #     mean = (transformed_sample[\"image\"].float()[0].mean(), transformed_sample[\"image\"].float()[1].mean(), transformed_sample[\"image\"].float()[2].mean())\n",
        "  #     std  = (transformed_sample[\"image\"].float()[0].std(),  transformed_sample[\"image\"].float()[1].std(),  transformed_sample[\"image\"].float()[2].std())\n",
        "  #     norm = Normalize(mean, std)\n",
        "  #     transformed_sample = norm(transformed_sample)\n",
        "\n",
        "  ax[i+1].set_title(type(tsfrm).__name__)\n",
        "  ax[i+1].imshow(transformed_sample[\"image\"].transpose(0,1).transpose(1,2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX0yo5NVB37G"
      },
      "source": [
        "## **DATALOADERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVVJdmKBB6hV"
      },
      "outputs": [],
      "source": [
        "pokemon_dataset = PokemonImageDataset(list_of_pokemon_images = list_of_images, \n",
        "                                      images_labels          = list_of_labels,\n",
        "                                      transform              = transforms.Compose([Rescale(256),\n",
        "                                                                                   RandomCrop(224)]\n",
        "                                                                                  ))\n",
        "\n",
        "pokemon_dataloader = DataLoader(pokemon_dataset, batch_size = 4, shuffle = True, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "bT1sZcaNIcpX",
        "outputId": "33659e94-cbbb-4cb8-bd5f-b594d3028cb1"
      },
      "outputs": [],
      "source": [
        "for i_batch, sample_batched in enumerate(pokemon_dataloader):\n",
        "  image = sample_batched[\"image\"]\n",
        "  label = sample_batched[\"label\"]\n",
        "  print(f\"batch number : {i_batch}, batch shape : {image.size()}, batch[0] shape{image[0].size()}, label {label}\")\n",
        "  \n",
        "  if i_batch == 3:\n",
        "    images_batch, label_batch = sample_batched['image'],sample_batched['label']\n",
        "    batch_len = images_batch.shape[0]\n",
        "    fig,ax = plt.subplots(1,batch_len, figsize = (20,10))\n",
        "    for i in range(batch_len):\n",
        "      ax[i].imshow(images_batch[i].permute(1,2,0))\n",
        "      ax[i].set_title(f\"true label : {list_of_pokemons[label_batch[i]]}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmt3yMNoCbLI"
      },
      "outputs": [],
      "source": [
        "train, test_set = train_test_split(pokemon_dataset, test_size=0.2, train_size = 0.8, random_state = 42,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZo2jrkhGCsx"
      },
      "outputs": [],
      "source": [
        "train_set, validation_set =  train_test_split(train, test_size=0.25, train_size = 0.75, random_state = 42,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b67fbEi1GKod",
        "outputId": "21cc4b69-821b-4c02-eef4-b28bc0bcafc2"
      },
      "outputs": [],
      "source": [
        "print(\"training set size : {}, validation set size : {}, test set size : {}\".format(len(train_set),len(validation_set),len(test_set)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpZQXhU_OD8I"
      },
      "outputs": [],
      "source": [
        "dataloaders = {'train': DataLoader(train_set, batch_size = 10, shuffle = True, num_workers=0), \n",
        "               'val'  : DataLoader(validation_set, batch_size = 10, shuffle = True, num_workers=0), \n",
        "               'test' : DataLoader(test_set, batch_size = 10, shuffle = True, num_workers=0)} \n",
        "\n",
        "dataset_sizes = {x: y for x,y in zip(['train', 'val','test'],[len(train_set),len(validation_set),len(test_set)])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfwGj0JCIXvW",
        "outputId": "8ba9f767-a527-4bd5-f003-15c5dfb0c3d8"
      },
      "outputs": [],
      "source": [
        "print(dataset_sizes[\"val\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59oNNL_DO1qi",
        "outputId": "549d4617-4f6e-493b-9bcf-d2c00db572a1"
      },
      "outputs": [],
      "source": [
        "for dictionary in dataloaders['train']:\n",
        "  print(dictionary['image'].shape)\n",
        "  if i == 3: break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fngS-aGkoDHS"
      },
      "source": [
        "## TRAINING THE NETWORK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlxd6h8LoQLi"
      },
      "outputs": [],
      "source": [
        "model = AlexNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "num_epochs = 5\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo0aXlpZG8Id"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOb-zX-goWTo",
        "outputId": "0c1e6ac2-2a26-406c-8dd0-7a50d98ea39f"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeFRVtNvCOj2"
      },
      "source": [
        "## SPLIT : TRAINING VALIDATION & TEST SET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jZVHmAeJ-Ay",
        "outputId": "45e32c2d-4880-406d-bb8f-7840ae19b8f9"
      },
      "outputs": [],
      "source": [
        "since = time.time()\n",
        "best_accuracy = 0.\n",
        "\n",
        "train_accuracy = []\n",
        "validation_accuracy = []\n",
        "\n",
        "train_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "  print('-'*10)\n",
        "\n",
        "  for phase in ['train','val']:\n",
        "    if phase == 'train':\n",
        "      model.train() # set model to training mode\n",
        "    else:\n",
        "      model.eval()   # set model to evaluate mode (tested on the validation set first)\n",
        "\n",
        "    running_loss, running_corrects = 0.0, 0\n",
        "\n",
        "    for running_data in dataloaders[phase]:\n",
        "      images = running_data['image']\n",
        "      labels = running_data['label']\n",
        "\n",
        "      # print(f\"images shape : {images.shape} , labels : {labels}\")\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "      # print(\"setting zero gradients\")\n",
        "\n",
        "      # forward\n",
        "      # track history if only in train\n",
        "\n",
        "      with torch.set_grad_enabled(phase == 'train'):\n",
        "        # print(\"Alla fine l'input gli Ã¨ piaciuto\")\n",
        "        outputs = model(images.float())\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "      # backward + optimize only if in training phase\n",
        "        if phase == 'train':\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      running_loss += loss.item() * images.size(0)\n",
        "      running_corrects += torch.sum(preds == labels.data)\n",
        "    # (Da rivedere) call of the progress step per epoch\n",
        "    if phase == 'train': \n",
        "      scheduler.step()\n",
        "    \n",
        "    #loss and accuracy evaluation per each epoch\n",
        "    epoch_loss = running_loss / dataset_sizes[phase]\n",
        "    epoch_accuracy = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "    print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_accuracy:.4f}')\n",
        "    if phase == 'train':\n",
        "      train_accuracy.append(epoch_accuracy)\n",
        "      train_loss.append(epoch_loss)\n",
        "    if phase == 'val':\n",
        "      validation_accuracy.append(epoch_accuracy)\n",
        "      validation_loss.append(epoch_loss)\n",
        "      \n",
        "    if phase == 'val' and epoch_accuracy > best_accuracy:\n",
        "      best_accuracy = epoch_accuracy\n",
        "      # best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    \n",
        "    print()\n",
        "\n",
        "time_elapsed = time.time() - since\n",
        "print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "print(f'Best val Acc: {best_accuracy:4f}')\n",
        "\n",
        "# load best model weights\n",
        "# model.load_state_dict(best_model_wts)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQpIMBIgM15e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "SuRreKntLVso",
        "outputId": "44150932-7f90-4810-c19f-83607314debc"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "was_training = model.training\n",
        "\n",
        "with torch.no_grad():\n",
        "  for running_data in dataloaders['test']:\n",
        "    images = running_data['image']\n",
        "    labels = running_data['label']\n",
        "\n",
        "    outputs = model(images.float())\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    fig,ax = plt.subplots(1,10, figsize=(30,15))\n",
        "    for index,images in enumerate(images):\n",
        "      ax[index].imshow(images.permute(1,2,0))\n",
        "      ax[index].set_title(f\"predicted: {list_of_pokemons[preds[index]]}\")\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvDLp7--X28A"
      },
      "source": [
        "# Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "KGku4UvqX2hn",
        "outputId": "96c25f6b-06b6-404b-cad4-d374b101ac64"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_accuracy,'-o')\n",
        "plt.plot(validation_accuracy,'-o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train','Validation'])\n",
        "plt.title('Train vs Validation Accuracy')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "C4tYv2yOm7e3",
        "outputId": "b990fd10-fa13-4f05-8e85-baaa322aaafd"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_loss,'-o')\n",
        "plt.plot(validation_loss,'-o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train','Validation'])\n",
        "plt.title('Train vs Validation Loss')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq5ayHV5KDZl",
        "outputId": "72b4d178-5a4f-4385-c7c8-c8dbf736f140"
      },
      "outputs": [],
      "source": [
        "pokemon_dataset[1]['image'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oML35yT8Q4rK",
        "outputId": "531f9854-2213-4180-9c50-d47de6d08463"
      },
      "outputs": [],
      "source": [
        "test = pokemon_dataset[3][\"image\"]\n",
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "nZT0QH6mRH4n",
        "outputId": "2a58b155-165e-46b4-b107-f6b64c6aa1fa"
      },
      "outputs": [],
      "source": [
        "plt.imshow(test.permute(1,2,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "MVyXuaPsKt1x",
        "outputId": "7d73f39b-2c45-4659-98bf-75ac50cff663"
      },
      "outputs": [],
      "source": [
        "plt.imshow(pokemon_dataset[10]['image'][:3,:].permute(1,2,0)) # deal with 4 channel images -> eliminate 1 channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "HB4oubtJMNhg",
        "outputId": "9a693021-b64a-433c-8a49-72c655943d12"
      },
      "outputs": [],
      "source": [
        "plt.imshow(pokemon_dataset[1]['image'].expand(3,*pokemon_dataset[1]['image'].shape[1:]).permute(1,2,0)) # deal with 1 channel images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUOsNYIeUEHH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
