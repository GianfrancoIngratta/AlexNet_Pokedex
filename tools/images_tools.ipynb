{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1oGA4GXLmoBzlwm78csCv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jabb4/AlexNet_Pokedex/blob/main/tools/images_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "V_Pjy6j9BipV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caXokJHCAzpb"
      },
      "outputs": [],
      "source": [
        "class Rescale(object):\n",
        "  \"\"\"Rescale the image in a sample to a given size.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If tuple, output is\n",
        "            matched to output_size. If int, smaller of image edges is matched\n",
        "            to output_size keeping aspect ratio the same.\n",
        "  \"\"\"\n",
        "  def __init__(self, output_size):\n",
        "    assert isinstance(output_size, (int, tuple))\n",
        "    if isinstance(output_size, int):\n",
        "      self.output_size = (output_size, output_size)\n",
        "    else:\n",
        "      assert len(output_size) == 2\n",
        "      self.output_size = output_size\n",
        "  \n",
        "  def __call__(self, sample):\n",
        "    image, label = sample[\"image\"], sample[\"label\"]\n",
        "\n",
        "    # print(f\"shape before resize : {image.shape}\")\n",
        "    \n",
        "    resize = transforms.Resize(self.output_size)\n",
        "    \n",
        "    image = resize(image)\n",
        "    \n",
        "    # print(f\"shape after resize : {image.shape}\")\n",
        "\n",
        "    return {\"image\":image, \"label\":label}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomCrop(object):\n",
        "  \"\"\"Crop randomly the image in a sample.\n",
        "  Args:\n",
        "    output_size (tuple or int): Desired output size. If int, square crop is made\n",
        "  \"\"\"\n",
        "  def __init__(self, output_size):\n",
        "    assert isinstance(output_size, (int, tuple))\n",
        "    if isinstance(output_size, int):\n",
        "      self.output_size = (output_size, output_size)\n",
        "    else:\n",
        "      assert len(output_size) == 2\n",
        "      self.output_size = output_size\n",
        "  \n",
        "  def __call__(self, sample):\n",
        "    image, label = sample[\"image\"], sample[\"label\"]\n",
        "    \n",
        "    # print(f\"after RandomCrop : {image.shape}\")\n",
        "\n",
        "    crop = transforms.RandomCrop(self.output_size,pad_if_needed=True)\n",
        "\n",
        "    image = crop(image)\n",
        "\n",
        "    # print(f\"after RandomCrop : {image.shape}\")\n",
        "    # print(\"\")\n",
        "\n",
        "    return {\"image\":image, \"label\": label}"
      ],
      "metadata": {
        "id": "dCbjKvp0BblU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Normalize(object):\n",
        "  \n",
        "  \"\"\"Normalize a tensor image with mean and standard deviation.\n",
        "  This transform does not support PIL Image.\n",
        "  Given mean: ``(mean[1],...,mean[n])`` and std: ``(std[1],..,std[n])`` for ``n``\n",
        "  channels, this transform will normalize each channel of the input\n",
        "  ``torch.*Tensor`` i.e.,\n",
        "  ``output[channel] = (input[channel] - mean[channel]) / std[channel]``\n",
        "  .. note::\n",
        "      This transform acts out of place, i.e., it does not mutate the input tensor.\n",
        "  Args:\n",
        "      mean (sequence): Sequence of means for each channel.\n",
        "      std (sequence): Sequence of standard deviations for each channel.\n",
        "      inplace(bool,optional): Bool to make this operation in-place.\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, mean: tuple , std : tuple, inplace=False):\n",
        "    self.mean = mean\n",
        "    self.std = std\n",
        "    self.inplace = inplace\n",
        "  \n",
        "  def __call__(self, sample):\n",
        "    image, label = sample['image'], sample['label']\n",
        "\n",
        "    norm = transforms.Normalize(self.mean,self.std)\n",
        "    \n",
        "    image = norm(image.float())\n",
        "\n",
        "    return {\"image\":image, \"label\": label}"
      ],
      "metadata": {
        "id": "0Fur0Ww4BgXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToTensor(object):\n",
        "  \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "  def __call__(self,sample):\n",
        "    image, label = sample[\"image\"], sample[\"label\"]\n",
        "    image, label = transforms.ToTensor()(image), transforms.ToTensor()(label)\n",
        "    print(f\"after ToTensor : {image.shape}\")\n",
        "    return {\"image\": image, \"label\": label}"
      ],
      "metadata": {
        "id": "yxR496sbBnod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mHh-ZtntBrnM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}